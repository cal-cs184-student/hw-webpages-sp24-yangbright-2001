<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Liang Yang</h2>


<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>



<h2 align="middle">Overview</h2>
<p>
  In this project, we will implement the core routines of a physically-based renderer using a pathtracing algorithm. This project utilizes the ideas covered in class recently, 
  including ray-scene intersection, acceleration structures, and physically based lighting and materials. 
  By the time we complete implementing the project, we'll be able to generate some realistic pictures given enough patience and CPU time. 
  The project consists of 5 parts, which are ray generation and scene intersection, bvh, direct illumination, global illumination and adaptive sampling.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
    The ray is parametrized by r(t) = o + td, where o is the original of the ray, and d is the direction of the ray. In this problem, we first need 
    to transform the point (x,y) in the image space to camera space, we can then generate such ray in the camera space, given the mapping point (x',y',-1)
    and the origin (camera position). Later, we transform such ray into world space. To generate pixel samples with (x,y) to be the bottom left corner and unit length, 
    we first need to generate ns_aa random rays using generate_ray() function, then we calculate the radiance along the array, finally, we sum up the radiance
    and then divide by the number of sample. The resulting vector3D will be the updated value of the pixel.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    The triangle intersection algorithm is implemented using the Moller-Trumbore Algorithm introduced in lecture slides, which improves the intersection speed.
    We are given the origin and direction vector of the ray in the Ray class, the coordinate of the triangle is also given in the Triangle class. Then we perform the
    calculation process in the algorithm, which gives us a vector3D and barycentric coordinate (1-b1-b2, b1, b2) of the triangle. We need to perform a check for 
    whether the coordinate is valid with every value lies between 0 and 1. Moreover, we need to check whether t lies between r.min_t and r.max_t to be valid within
    the ray. 
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>

<p>
    after finishing task3, the rendered image should look like the ones below 
</p>

<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/CBempty.png" align="middle" width="400px"/>
        <figcaption>CBempty.dae</figcaption>
      </td>
      <td>
        <img src="images/CBspheres.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/banana.png" align="middle" width="400px"/>
        <figcaption>banana.dae</figcaption>
      </td>
      
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    We first compute the bounding box of the primitives, and initialize a new BVHNode with that bounding box. 
    Then we determine whether it is a leaf node or not by counting the number of primitives in the list and compare whether
    it is greater than max_leaf_size. If it is a leaf, we set its start and end attribute to be the original start and end.
    If not, we divide the primitives into left and right collection. The division process is implemented by dividing the edge axis of 
    box with the greatest length, then we divide the axis based on the average of the centroid of the primitives to avoid all primitives
    lies on the same side and lead to segfault. If the centroid of an object is equal to the average value, it will be classified to the
    side with fewer primitives, to again avoid all primitives lying in the same side. We then finish dividing the primitives into 2 halves,
    later on, we assign the current node's left and right child node by recursively calling the construct_bvh function, with the start
    and end parameters to be the start and end iterator of the new divided vector of child nodes.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/maxplanck.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
      <td>
        <img src="images/cow.png" align="middle" width="400px"/>
        <figcaption>cow.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/CBlucy.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>

    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
  <div align="center">
    <table style="width=100%">
        <tr>
            <td align="middle">
            <img src="images/2_speed.png" width="480px" />
            <figcaption align="middle">Speed for rendering cow with bvh acceleration</figcaption>
        </tr>
    </table>
  </div>
</p>
<br>
<p>
  As we can see from the above, the speed for rendering the cow with bvh is 0.0265s, while the speed without acceleration is 40s.
  Moreover,  the speed for rendering CBlucy is 0.0259s, the speed for rendering maxplanck is 0.0295s
</p>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    For the uniform hemisphere sampling, we created a coordinate system at isect with the make_coord_space() function.
    Next, we calculate the point of hit, given the ray. We wrote a loop which samples directions over the hemisphere.
    Every time we sample, we first transfrom the coordinate into world space, then we trace a new ray. At intersection,
    the weight of the light to the intersection point will be calculated
</p>
<p>
  For the light importance sampling, the construction of coordinate system is similar to uniform sampling. At each loop for light source in the scene, we sample a direction to the light, tracing
  from the intersection point. At the mean time, we calculate the distance to the light and pdf of the sampled direction. Furthermore, we checked if there
  are occlusion between point and the light source.  The weight of the sample light to the illumination is calculated.
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<p>
  uniform hemisphere sampling:
</p>
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <br>
    <tr align="center">
      <td>
        <img src="images/CBbunny_H_16_8.png" align="middle" width="400px"/>
        <figcaption>CBbunny_H_16_8.png.dae</figcaption>
      </td>
      <td>
        <img src="images/CBbunny_H_64_32.png" align="middle" width="400px"/>
        <figcaption>CBbunny_H_64_32.png.dae</figcaption>
      </td>
    </tr>
    
  </table>
</div>
<br>

<p>
  Light importance sampling:
</p>

<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <br>
    <tr align="center">
      <td>
        <img src="images/bunny_1_1.png" align="middle" width="400px"/>
        <figcaption>bunny_1_1.png.dae</figcaption>
      </td>
      <td>
        <img src="images/bunny_64_32.png" align="middle" width="400px"/>
        <figcaption>bunny_64_32.png.dae</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/dragon_64_32.png" align="middle" width="400px"/>
        <figcaption>dragon_64_32.dae</figcaption>
      </td>
      
    </tr>
    <br>
  </table>
</div>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_64_32_1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (bunny_64_32_1.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_64_32_4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (bunny_64_32_4.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_64_32_16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (bunny_64_32_16.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_64_32_64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (bunny_64_32_64.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    We use the light importance sampling, from which we see that as the number of light rays increase, the noise level decrease.
    The details of the image gets much clearer.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    uniform hemisphere sampling does not prioritize the light source, which distributes ray evenly, it requires more calculations and has higher time complexities.
    Light importance sampling is more efficient, concentrating on the computational processes that are more needed.
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    First, we check whether max_ray_depth is 1 and isAccumBounces is set to 0, the result of one_bounce_radiance() will be return.
    Otherwise, the result of one_bounce_radiance() is added to accumulate the contribution of lights. The accumulated light contribution is calculated during recursion.
    Value r.depth controls the recursion depth.
    Indirect lighting is sample by the sample_f() and the corresponding pdf is calculated. At each bounce,
    the contribution of the current path to the final color is calculated by multiplying the BSDF value with dot(incoming dir, surface material), divided by the pdf.

</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>

<p>
  the left figure is direct illumination, and the right figure is indirect illumination
</p>

<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/1.png" align="middle" width="400px"/>
        <figcaption>example1.dae</figcaption>
      </td>
      <td>
        <img src="images/2.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<p>
  the left figure is only direct illumination, and the right figure is only indirect illumination
</p>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/3.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/4.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/5.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/6.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/7.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/8.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/10.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/11.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/12.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/13.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/14.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/15.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/16.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/17.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling reduces the computational complexities. In the implementation, we batches samples.
    At each batch, the pixel's color using mean radiance and variability using standard deviation is calculated. The 
    convergence testing is adopted to determine whether a color has been close to the true value. A tolerance is given
    as a threshold for stop the sampling process. Adaptive sampling dynamically adjusts to achieve the goal of offering more
    samples to pixels that require more details, improving the quality of rendering.
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_1.png" align="middle" width="400px"/>
        <figcaption>Rendered image (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_rate_1.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/dragon_1.png" align="middle" width="400px"/>
        <figcaption>Rendered image (example2.dae)</figcaption>
      </td>
      <td>
        <img src="images/dragon_rate_1.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (example2.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
